{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1052f2-a5b5-4a40-9c2c-4af4b0c369cb",
   "metadata": {},
   "source": [
    "## Load training transaction data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 5,
>>>>>>> 842b2139bbfad85d5a16d480feeca0237ee485f7
=======
   "execution_count": 31,
>>>>>>> 3e03193ef81191c40a4b1c641cc8ec8326a05e9b
   "id": "ba36f092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>unix_time</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:00:18</td>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Banks</td>\n",
       "      <td>F</td>\n",
       "      <td>561 Perry Cove</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>NC</td>\n",
       "      <td>28654</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>3495</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "      <td>1988-03-09</td>\n",
       "      <td>0b242abb623afc578575680df30655b9</td>\n",
       "      <td>1325376018</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:00:44</td>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>Gill</td>\n",
       "      <td>F</td>\n",
       "      <td>43039 Riley Greens Suite 393</td>\n",
       "      <td>Orient</td>\n",
       "      <td>WA</td>\n",
       "      <td>99160</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>149</td>\n",
       "      <td>Special educational needs teacher</td>\n",
       "      <td>1978-06-21</td>\n",
       "      <td>1f76529f8574734946361c461b024d99</td>\n",
       "      <td>1325376044</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:00:51</td>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Sanchez</td>\n",
       "      <td>M</td>\n",
       "      <td>594 White Dale Suite 530</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>ID</td>\n",
       "      <td>83252</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>4154</td>\n",
       "      <td>Nature conservation officer</td>\n",
       "      <td>1962-01-19</td>\n",
       "      <td>a1a22d70485983eac12b5b88dad1cf95</td>\n",
       "      <td>1325376051</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:01:16</td>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Jeremy</td>\n",
       "      <td>White</td>\n",
       "      <td>M</td>\n",
       "      <td>9443 Cynthia Court Apt. 038</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>MT</td>\n",
       "      <td>59632</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>1939</td>\n",
       "      <td>Patent attorney</td>\n",
       "      <td>1967-01-12</td>\n",
       "      <td>6b849c168bdad6f867558c3793159a81</td>\n",
       "      <td>1325376076</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:03:06</td>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Tyler</td>\n",
       "      <td>Garcia</td>\n",
       "      <td>M</td>\n",
       "      <td>408 Bradley Rest</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>VA</td>\n",
       "      <td>24433</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>99</td>\n",
       "      <td>Dance movement psychotherapist</td>\n",
       "      <td>1986-03-28</td>\n",
       "      <td>a41d7549acf90789359a9aa5346dcb46</td>\n",
       "      <td>1325376186</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
       "0           0   2019-01-01 00:00:18  2703186189652095   \n",
       "1           1   2019-01-01 00:00:44      630423337322   \n",
       "2           2   2019-01-01 00:00:51    38859492057661   \n",
       "3           3   2019-01-01 00:01:16  3534093764340240   \n",
       "4           4   2019-01-01 00:03:06   375534208663984   \n",
       "\n",
       "                             merchant       category     amt      first  \\\n",
       "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
       "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
       "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
       "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
       "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
       "\n",
       "      last gender                        street            city state    zip  \\\n",
       "0    Banks      F                561 Perry Cove  Moravian Falls    NC  28654   \n",
       "1     Gill      F  43039 Riley Greens Suite 393          Orient    WA  99160   \n",
       "2  Sanchez      M      594 White Dale Suite 530      Malad City    ID  83252   \n",
       "3    White      M   9443 Cynthia Court Apt. 038         Boulder    MT  59632   \n",
       "4   Garcia      M              408 Bradley Rest        Doe Hill    VA  24433   \n",
       "\n",
       "       lat      long  city_pop                                job         dob  \\\n",
       "0  36.0788  -81.1781      3495          Psychologist, counselling  1988-03-09   \n",
       "1  48.8878 -118.2105       149  Special educational needs teacher  1978-06-21   \n",
       "2  42.1808 -112.2620      4154        Nature conservation officer  1962-01-19   \n",
       "3  46.2306 -112.1138      1939                    Patent attorney  1967-01-12   \n",
       "4  38.4207  -79.4629        99     Dance movement psychotherapist  1986-03-28   \n",
       "\n",
       "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
       "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
       "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
       "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
       "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
       "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the data\n",
    "df_tr = pd.read_csv(\"data/fraudTrain.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e287a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions in the training dataset :  1296675\n",
      "Number of duplicated transactions : 0\n"
     ]
    }
   ],
   "source": [
    "# Drop the column named 'Unnamed: 0' (unnecessary index column)\n",
    "df_tr = df_tr.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Print the total number of transactions in the training dataset\n",
    "print(\"Number of transactions in the training dataset : \", len(df_tr))\n",
    "\n",
    "# Identify duplicated rows in the dataset \n",
    "duplicate_rows = df_tr[df_tr.duplicated()]\n",
    "print(\"Number of duplicated transactions :\", len(duplicate_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e01c68c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       missing_count  missing_percent\n",
      "trans_date_trans_time              0              0.0\n",
      "cc_num                             0              0.0\n",
      "merchant                           0              0.0\n",
      "category                           0              0.0\n",
      "amt                                0              0.0\n",
      "first                              0              0.0\n",
      "last                               0              0.0\n",
      "gender                             0              0.0\n",
      "street                             0              0.0\n",
      "city                               0              0.0\n",
      "state                              0              0.0\n",
      "zip                                0              0.0\n",
      "lat                                0              0.0\n",
      "long                               0              0.0\n",
      "city_pop                           0              0.0\n",
      "job                                0              0.0\n",
      "dob                                0              0.0\n",
      "trans_num                          0              0.0\n",
      "unix_time                          0              0.0\n",
      "merch_lat                          0              0.0\n",
      "merch_long                         0              0.0\n",
      "is_fraud                           0              0.0\n"
     ]
    }
   ],
   "source": [
    "# Detect missing values\n",
    "missing_counts = df_tr.isna().sum()\n",
    "missing_percent = (missing_counts / len(df_tr)) * 100\n",
    "\n",
    "# Combine into one table\n",
    "missing_summary = pd.DataFrame({\n",
    "    'missing_count': missing_counts,\n",
    "    'missing_percent': missing_percent\n",
    "}).sort_values(by='missing_percent', ascending=False)\n",
    "\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c8716e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trans_date_trans_time    datetime64[ns]\n",
       "cc_num                   string[python]\n",
       "merchant                       category\n",
       "category                       category\n",
       "amt                             Float64\n",
       "first                          category\n",
       "last                           category\n",
       "gender                         category\n",
       "street                         category\n",
       "city                           category\n",
       "state                          category\n",
       "zip                            category\n",
       "lat                             Float64\n",
       "long                            Float64\n",
       "city_pop                          Int64\n",
       "job                            category\n",
       "dob                      datetime64[ns]\n",
       "trans_num                string[python]\n",
       "unix_time                         Int64\n",
       "merch_lat                       Float64\n",
       "merch_long                      Float64\n",
       "is_fraud                          Int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically convert the columns of df_tr to the best possible data types\n",
    "df_tr = df_tr.convert_dtypes()\n",
    "\n",
    "# Display the data types of all columns after conversion\n",
    "df_tr.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1a4c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans_date_trans_time    datetime64[ns]\n",
      "cc_num                           object\n",
      "merchant                       category\n",
      "category                       category\n",
      "amt                             Float64\n",
      "first                          category\n",
      "last                           category\n",
      "gender                         category\n",
      "street                         category\n",
      "city                           category\n",
      "state                          category\n",
      "zip                            category\n",
      "lat                             Float64\n",
      "long                            Float64\n",
      "city_pop                          Int64\n",
      "job                            category\n",
      "dob                      datetime64[ns]\n",
      "trans_num                        object\n",
      "unix_time                         Int64\n",
      "merch_lat                       Float64\n",
      "merch_long                      Float64\n",
      "is_fraud                          Int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert date/time columns\n",
    "df_tr['trans_date_trans_time'] = pd.to_datetime(df_tr['trans_date_trans_time'], errors='coerce')\n",
    "df_tr['dob'] = pd.to_datetime(df_tr['dob'], errors='coerce')\n",
    "\n",
    "# Keep IDs as string/object\n",
    "df_tr['cc_num'] = df_tr['cc_num'].astype(str)\n",
    "df_tr['trans_num'] = df_tr['trans_num'].astype(str)\n",
    "\n",
    "# Convert categorical/text columns\n",
    "categorical_cols = ['merchant', 'category', 'first', 'last', 'gender', \n",
    "                    'street', 'city', 'state', 'zip', 'job']\n",
    "for col in categorical_cols:\n",
    "    df_tr[col] = df_tr[col].astype('category')\n",
    "\n",
    "# Check final dtypes\n",
    "print(df_tr.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5dd65168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "0    0.994211\n",
       "1    0.005789\n",
       "Name: proportion, dtype: Float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of each class\n",
    "# The 'normalize=True' parameter converts counts into proportions\n",
    "df_tr['is_fraud'].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc324841-9b08-47d8-8b59-ed1157cff6cf",
   "metadata": {},
   "source": [
    "## Check uniqueness of cc_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e79e82-e1b0-4850-8660-0b31448c5954",
   "metadata": {},
   "source": [
    "#### Si cc_num correspond réellement à une carte unique, alors toutes les transactions ayant la même cc_num devraient avoir les mêmes valeurs de first, last ,gender et dob.\n",
    "#### Hypothèse : cc_num correspond réellement à une carte unique."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 36,
>>>>>>> 3e03193ef81191c40a4b1c641cc8ec8326a05e9b
   "id": "9b81b66e-05d8-4470-839f-c08c3d006643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each cc_num value corresponds to a unique combination of (first, last, gender, dob).\n"
     ]
    }
   ],
   "source": [
    "# Count how many distinct (first, last, gender, dob) combinations exist for each cc_num\n",
    "combo_counts = (\n",
    "    df_tr.groupby(\"cc_num\")[[\"first\", \"last\", \"gender\", \"dob\"]]\n",
    "      .nunique()\n",
    ")\n",
    "\n",
    "# Check if (first, last, gender, dob) are always single-valued per cc_num\n",
    "violations = combo_counts[(combo_counts[\"first\"] > 1) | (combo_counts[\"last\"] > 1) | (combo_counts[\"gender\"] > 1) | (combo_counts[\"dob\"] > 1)]\n",
    "\n",
    "if violations.empty:\n",
    "    print(\"Each cc_num value corresponds to a unique combination of (first, last, gender, dob).\")\n",
    "else:\n",
    "    print(\"Some cc_num values map to multiple (first, last, gender, dob) combinations:\")\n",
    "    print(violations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ff5d13-34d5-4751-b4aa-5600791cd6b6",
   "metadata": {},
   "source": [
    "## Detect cc_num with multiple transactions at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c6132-2a53-400e-a311-90a07f60a791",
   "metadata": {},
   "source": [
    "#### Une carte bancaire réelle ne peut normalement pas effectuer plusieurs transactions strictement au même instant (même seconde).\n",
    "#### Hypothèse : cc_num représente un identifiant quasi-unique d'une carte réelle."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 43,
>>>>>>> 3e03193ef81191c40a4b1c641cc8ec8326a05e9b
   "id": "e9d543c8-9646-4992-8c78-0a3b249c975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some cc_num values have multiple distinct trans_num within the same second:\n",
      "                                           count\n",
      "cc_num              trans_date_trans_time       \n",
      "180036456789979     2019-08-11 19:26:21        2\n",
      "2383461948823908    2019-12-06 08:43:10        2\n",
      "3506042666828517    2019-04-18 17:32:31        2\n",
      "3517527805128735    2020-03-14 02:15:53        2\n",
      "3533012926413100    2020-05-21 15:52:29        2\n",
      "3553629419254918    2019-03-10 02:31:27        2\n",
      "3560318482131952    2019-10-31 01:16:14        2\n",
      "3595192916105588    2019-01-16 05:51:27        2\n",
      "374930071163758     2019-06-16 23:58:35        2\n",
      "375082648741747     2019-06-28 21:25:50        2\n",
      "4715741951931168360 2020-03-24 17:28:55        2\n",
      "4736845434667908128 2019-12-25 00:01:08        2\n",
      "4904681492230012    2020-03-15 00:34:58        2\n",
      "4933461930348832    2019-04-14 16:33:06        2\n",
      "581686439828        2019-08-26 21:47:51        2\n",
      "6011504998544485    2019-09-23 16:43:49        2\n",
      "6011652924285713    2020-06-02 20:14:33        2\n",
      "630423337322        2019-12-08 14:36:51        2\n",
      "6538441737335434    2019-08-06 18:17:56        2\n",
      "676173792455        2019-12-14 01:11:03        2\n",
      "Number of cc_num with more than one distinct trans_num at the same second: 20\n"
     ]
    }
   ],
   "source": [
    "# Group by cc_num and trans_date_trans_time and count distinct trans_num\n",
    "counts_df = (\n",
    "    df_tr.groupby([\"cc_num\", \"trans_date_trans_time\"])['trans_num']\n",
    "      .nunique()\n",
    "      .to_frame('count')\n",
    ")\n",
    "\n",
    "# Keep only (cc_num, trans_date_trans_time) paris with distinct trans_num > 1\n",
    "duplicates_same_second = counts_df[counts_df[\"count\"] > 1]\n",
    "\n",
    "if duplicates_same_second.empty:\n",
    "    print(\"No cc_num has more than one distinct trans_num at the same second.\")\n",
    "else:\n",
<<<<<<< HEAD
    "    print(\"Some card1 values have multiple distinct TransactionIDs within the same second:\")\n",
    "    print(duplicates_same_second.sort_values(\"count\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b7f92-a237-4365-afe5-87b35543795b",
   "metadata": {},
   "source": [
    "## Detect card1 transactions repeated within 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106ffad-04b4-4b33-b87a-0a84420d0ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of repeated card1 events within 1 minute: 19828\n",
      "       TransactionDT  diff_sec\n",
      "card1                         \n",
      "15497       15187923       0.0\n",
      "7919         7310775       0.0\n",
      "15548        8695812       0.0\n",
      "3570         7429783       0.0\n",
      "7919         7937752       0.0\n",
      "...              ...       ...\n",
      "7919        13174656      60.0\n",
      "12260        1902332      60.0\n",
      "2631         2038734      60.0\n",
      "15582        3020192      60.0\n",
      "10486        6386533      60.0\n",
      "\n",
      "[19828 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sort by card1 and TransactionDT\n",
    "df = df_tr.sort_values([\"card1\", \"TransactionDT\"])\n",
    "\n",
    "# First, remove duplicate TransactionIDs to avoid comparing the same transaction\n",
    "df = df.drop_duplicates(subset=[\"card1\", \"TransactionID\"])\n",
    "\n",
    "# Compute difference between consecutive transactions for each card1\n",
    "df[\"diff_sec\"] = df.groupby(\"card1\")[\"TransactionDT\"].diff()\n",
    "\n",
    "# Mark transactions repeated within 60 seconds\n",
    "df[\"repeated_within_1min\"] = df[\"diff_sec\"] <= 60\n",
    "\n",
    "# Extract only the repeated occurrences\n",
    "repeated = df[df[\"repeated_within_1min\"] == True]\n",
    "\n",
    "print(\"Number of repeated card1 events within 1 minute:\", len(repeated))\n",
    "print(repeated[[\"card1\", \"TransactionDT\", \"diff_sec\"]].set_index(\"card1\").sort_values(\"diff_sec\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fca7f-4818-4493-a648-0fcfff026290",
   "metadata": {},
   "source": [
    "## Detect (card1, card2, card3, card4, card5, card6) with multiple transactions at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109c292-bf02-4743-b645-99a772907e7f",
   "metadata": {},
   "source": [
    "#### Une carte réelle ne doit pas effectuer plusieurs transactions distinctes à la même seconde.\n",
    "#### Hypothèse : Le tuple complet (card1, card2, card3, card4, card5, card6) représente un identifiant quasi-unique d'une carte réelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da60935-3e87-4de4-b267-af8041c9d388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some (card1, card2, card3, card4, card5, card6) values have multiple distinct TransactionIDs within the same second:\n",
      "                                                        count\n",
      "card1 card2 card3 card4      card5 card6 TransactionDT       \n",
      "9288  512.0 150.0 mastercard 224.0 debit 9474817            8\n",
      "13780 298.0 150.0 visa       226.0 debit 7236588            5\n",
      "10023 111.0 150.0 visa       226.0 debit 8218707            4\n",
      "                                         8218708            4\n",
      "2744  490.0 150.0 visa       195.0 debit 8468062            4\n",
      "...                                                       ...\n",
      "17188 321.0 150.0 visa       226.0 debit 11305705           2\n",
      "                                         11832962           2\n",
      "                                         14525480           2\n",
      "17335 129.0 150.0 visa       226.0 debit 7414661            2\n",
      "17517 369.0 150.0 mastercard 224.0 debit 8739176            2\n",
      "\n",
      "[142 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by (card1, card2, card3, card4, card5, card6) and TransactionDT and count distinct TransactionIDs\n",
    "counts_df = (\n",
    "    df_tr.groupby([\"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"TransactionDT\"])['TransactionID']\n",
    "      .nunique()\n",
    "      .to_frame('count')\n",
    ")\n",
    "\n",
    "# Keep only duplicates: distinct TransactionIDs > 1\n",
    "duplicates_same_second = counts_df[counts_df[\"count\"] > 1]\n",
    "\n",
    "if duplicates_same_second.empty:\n",
    "    print(\"No (card1, card2, card3, card4, card5, card6) has more than one distinct TransactionID in the same second.\")\n",
    "else:\n",
    "    print(\"Some (card1, card2, card3, card4, card5, card6) values have multiple distinct TransactionIDs within the same second:\")\n",
    "    print(duplicates_same_second.sort_values(\"count\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4890b91f-c523-4255-a46f-a1c557a471ac",
   "metadata": {},
   "source": [
    "## Detect (id_01,..., id_38) with multiple transactions at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5384c0-0510-4a3a-95d3-bfd48af32499",
   "metadata": {},
   "source": [
    "#### Si l’on considère l’ensemble de ces colonnes (id_xx) comme représentant une personne unique, alors une même personne ne peut pas effectuer plusieurs transactions exactement au même instant (même seconde).\n",
    "#### Hypothèse : chaque (id_01,..., id_38) correspond à une personne unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b285d7a-2752-4abf-a019-2ca9f0d3592e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some (id_01,..., id_38) values have multiple distinct TransactionIDs within the same second:\n",
      "                                                     count\n",
      "full_id                               TransactionDT       \n",
      "_____________________________________ 9474817            8\n",
      "                                      4397066            5\n",
      "                                      7236588            5\n",
      "                                      11576951           5\n",
      "                                      7337054            4\n",
      "...                                                    ...\n",
      "                                      4921518            2\n",
      "                                      4922292            2\n",
      "                                      4922397            2\n",
      "                                      4925611            2\n",
      "                                      4917063            2\n",
      "\n",
      "[10030 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df_id = pd.read_csv(\"data/train_identity.csv\")\n",
    "df = df_tr.merge(df_id, on=\"TransactionID\", how=\"left\")\n",
    "\n",
    "# Créer un identifiant combiné\n",
    "id_cols = [c for c in df_id.columns if c.startswith(\"id_\")]\n",
    "df[\"full_id\"] = df[id_cols].fillna(\"\").astype(str).agg(\"_\".join, axis=1)\n",
    "\n",
    "# Group by card1 and TransactionDT and count distinct TransactionIDs\n",
    "counts_df = (\n",
    "    df.groupby([\"full_id\", \"TransactionDT\"])['TransactionID']\n",
    "      .nunique()\n",
    "      .to_frame('count')\n",
    ")\n",
    "\n",
    "# Keep only duplicates: distinct TransactionIDs > 1\n",
    "duplicates_same_second = counts_df[counts_df[\"count\"] > 1]\n",
    "\n",
    "if duplicates_same_second.empty:\n",
    "    print(\"No (id_01,..., id_38) has more than one distinct TransactionID in the same second.\")\n",
    "else:\n",
    "    print(\"Some (id_01,..., id_38) values have multiple distinct TransactionIDs within the same second:\")\n",
    "    print(duplicates_same_second.sort_values(\"count\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cf60c6-4bdc-41cc-9588-20ae8fd4c6cc",
   "metadata": {},
   "source": [
    "## Detect (id_01,..., id_38, card1,..., card6) with multiple transactions at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbc341-f2c5-4757-84d5-bd56dec87582",
   "metadata": {},
   "source": [
    "#### Si l’on considère l’ensemble de ces colonnes (id_xx, cardx) comme représentant une personne unique, alors une même personne ne peut pas effectuer plusieurs transactions exactement au même instant (même seconde).\n",
    "#### Hypothèse : chaque (id_01,..., id_38, card1,..., card6) correspond à une personne unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb64b560-7e4e-4eb0-8ea3-f05dbec517f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some (id_01,..., id_38, card1,..., card6) values have multiple distinct TransactionIDs within the same second:\n",
      "                                                                                              count\n",
      "full_id                               card1 card2 card3 card4      card5 card6 TransactionDT       \n",
      "_____________________________________ 9288  512.0 150.0 mastercard 224.0 debit 9474817            8\n",
      "                                      13780 298.0 150.0 visa       226.0 debit 7236588            5\n",
      "                                      10023 111.0 150.0 visa       226.0 debit 8218707            4\n",
      "                                                                               8218708            4\n",
      "                                      2744  490.0 150.0 visa       195.0 debit 8468062            4\n",
      "...                                                                                             ...\n",
      "                                      17188 321.0 150.0 visa       226.0 debit 11305705           2\n",
      "                                                                               11832962           2\n",
      "                                                                               14525480           2\n",
      "                                      17335 129.0 150.0 visa       226.0 debit 7414661            2\n",
      "                                      17517 369.0 150.0 mastercard 224.0 debit 8739176            2\n",
      "\n",
      "[114 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by card1 and TransactionDT and count distinct TransactionIDs\n",
    "counts_df = (\n",
    "    df.groupby([\"full_id\", \"card1\", \"card2\", \"card3\", \"card4\", \"card5\", \"card6\", \"TransactionDT\"])['TransactionID']\n",
    "      .nunique()\n",
    "      .to_frame('count')\n",
    ")\n",
    "\n",
    "# Keep only duplicates: distinct TransactionIDs > 1\n",
    "duplicates_same_second = counts_df[counts_df[\"count\"] > 1]\n",
    "\n",
    "if duplicates_same_second.empty:\n",
    "    print(\"No (id_01,..., id_38, card1,..., card6) has more than one distinct TransactionID in the same second.\")\n",
    "else:\n",
    "    print(\"Some (id_01,..., id_38, card1,..., card6) values have multiple distinct TransactionIDs within the same second:\")\n",
    "    print(duplicates_same_second.sort_values(\"count\", ascending=False))\n"
=======
    "    print(\"Some cc_num values have multiple distinct trans_num within the same second:\")\n",
    "    print(duplicates_same_second.sort_values(\"count\", ascending=False))\n",
    "    print(\"Number of cc_num with more than one distinct trans_num at the same second:\", len(duplicates_same_second))\n"
>>>>>>> 3e03193ef81191c40a4b1c641cc8ec8326a05e9b
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python3.15",
   "language": "python",
   "name": "nom_du_kernel"
=======
   "display_name": "VGAE",
   "language": "python",
   "name": "vgae-env"
>>>>>>> 3e03193ef81191c40a4b1c641cc8ec8326a05e9b
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
