{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83ebe082-a787-4a46-b3e1-66a8ccf5a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import VGAE, NNConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07b4e4e4-1e97-4eb5-89de-d498b074c5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphe chargé : graphs/train/graph_batch_1.pt\n",
      "Graphe chargé : graphs/train/graph_batch_10.pt\n",
      "Graphe chargé : graphs/train/graph_batch_11.pt\n",
      "Graphe chargé : graphs/train/graph_batch_12.pt\n",
      "Graphe chargé : graphs/train/graph_batch_2.pt\n",
      "Graphe chargé : graphs/train/graph_batch_3.pt\n",
      "Graphe chargé : graphs/train/graph_batch_4.pt\n",
      "Graphe chargé : graphs/train/graph_batch_5.pt\n",
      "Graphe chargé : graphs/train/graph_batch_6.pt\n",
      "Graphe chargé : graphs/train/graph_batch_7.pt\n",
      "Graphe chargé : graphs/train/graph_batch_8.pt\n",
      "Graphe chargé : graphs/train/graph_batch_9.pt\n",
      "Graphe chargé : graphs/test/graph_batch_1.pt\n",
      "Graphe chargé : graphs/test/graph_batch_2.pt\n",
      "Graphe chargé : graphs/test/graph_batch_3.pt\n",
      "Graphe chargé : graphs/test/graph_batch_4.pt\n",
      "Graphe chargé : graphs/test/graph_batch_5.pt\n",
      "Graphe chargé : graphs/test/graph_batch_6.pt\n",
      "Graphe chargé : graphs/test/graph_batch_7.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11888/3133579107.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  g = torch.load(file_path)\n"
     ]
    }
   ],
   "source": [
    "def load_graphs(graph_dir):\n",
    "    # Vérification du dossier\n",
    "    graph_dir = Path(graph_dir)\n",
    "    if not graph_dir.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Le dossier '{graph_dir}' n'existe pas.\"\n",
    "        )\n",
    "    if not graph_dir.is_dir():\n",
    "        raise NotADirectoryError(\n",
    "            f\"'{graph_dir}' n'est pas un dossier valide.\"\n",
    "        )\n",
    "    graphs = []\n",
    "    # Charger tous les fichiers .pt\n",
    "    for file_path in sorted(graph_dir.glob(\"*.pt\")):\n",
    "        try:\n",
    "            g = torch.load(file_path)\n",
    "            graphs.append(g)\n",
    "            print(f\"Graphe chargé : {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement de {file_path} : {e}\")\n",
    "    return graphs\n",
    "\n",
    "# Charger les graphes\n",
    "train_graphs_dir = \"graphs/train\"\n",
    "test_graphs_dir = \"graphs/test\"\n",
    "\n",
    "train_graphs = load_graphs(train_graphs_dir)\n",
    "test_graphs = load_graphs(test_graphs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9e8148",
   "metadata": {},
   "source": [
    "## Split temporel (train / val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b73f0bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_graphs = len(train_graphs)\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "train_end = int(train_ratio * num_graphs)\n",
    "\n",
    "val_graphs   = train_graphs[train_end:]\n",
    "train_graphs = train_graphs[:train_end]\n",
    "\n",
    "\n",
    "# Créer un DataLoader pour l'entraînement\n",
    "# batch_size = nombre de graphes dans chaque batch\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_graphs,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_graphs,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_graphs,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1f7ed5",
   "metadata": {},
   "source": [
    "## Normalisation des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b739bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul mean/std sur tous les noeuds du train\n",
    "xs = torch.cat([g.x for g in train_graphs], dim=0)\n",
    "mean = xs.mean(dim=0)\n",
    "std = xs.std(dim=0) + 1e-6\n",
    "\n",
    "def normalize_graph(g):\n",
    "    g.x = (g.x - mean) / std\n",
    "    return g\n",
    "\n",
    "train_graphs = [normalize_graph(g) for g in train_graphs]\n",
    "val_graphs   = [normalize_graph(g) for g in val_graphs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf91b6",
   "metadata": {},
   "source": [
    "## Définir l’encodeur (avec NNConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "64bedc12-9005-4c8f-a4c6-19f08ff21a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNConvEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, edge_dim):\n",
    "        super(NNConvEncoder, self).__init__()\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        # MLP pour transformer edge_attr en matrice de poids pour NNConv\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(edge_dim, in_channels * 2 * out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # première couche NNConv\n",
    "        self.conv1 = NNConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=2 * out_channels,\n",
    "            nn=self.edge_mlp,\n",
    "            aggr='mean'\n",
    "        )\n",
    "\n",
    "        # couches mu et logvar\n",
    "        self.conv_mu = NNConv(\n",
    "            in_channels=2 * out_channels,\n",
    "            out_channels=out_channels,\n",
    "            nn=nn.Sequential(\n",
    "                nn.Linear(edge_dim, 2 * out_channels * out_channels),\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            aggr='mean'\n",
    "        )\n",
    "\n",
    "        self.conv_logvar = NNConv(\n",
    "            in_channels=2 * out_channels,\n",
    "            out_channels=out_channels,\n",
    "            nn=nn.Sequential(\n",
    "                nn.Linear(edge_dim, 2 * out_channels * out_channels),\n",
    "                nn.ReLU()\n",
    "            ),\n",
    "            aggr='mean'\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Couche 1\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        # Mu et LogVar pour VGAE\n",
    "        mu = self.conv_mu(x, edge_index, edge_attr)\n",
    "        logvar = self.conv_logvar(x, edge_index, edge_attr)\n",
    "        return mu, logvar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc25e1d",
   "metadata": {},
   "source": [
    "## Créer le modèle VGAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac52f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions extraites depuis UN graphe (tous ont la même structure)\n",
    "in_channels = train_graphs[0].x.shape[1]        # features par nœud\n",
    "out_channels = 32                               # dimension latente\n",
    "edge_dim = train_graphs[0].edge_attr.shape[1]   # features par arête\n",
    "\n",
    "encoder = NNConvEncoder(in_channels, out_channels, edge_dim)\n",
    "model = VGAE(encoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b6e415",
   "metadata": {},
   "source": [
    "## Définir l’optimiseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "511f0900",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0e2534",
   "metadata": {},
   "source": [
    "## Détecter le device (GPU si dispo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e71991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "device = torch.device(\"cpu\")\n",
    "# Déplacer le modèle\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ace071",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4fd048d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 10  # nombre d'époques sans amélioration\n",
    "best_loss = float('inf')\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f86bca",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e9053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Train Loss: 94408.2759 | Val Loss: 37110.8477\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    # ===== ENTRAÎNEMENT SUR LE PASSÉ =====\n",
    "    for t, data in enumerate(train_loader):\n",
    "        assert data.edge_index.dtype == torch.long\n",
    "        assert data.edge_index.min() >= 0\n",
    "        assert data.edge_index.max() < data.num_nodes\n",
    "        # Chaque data = 1 graphe temporel\n",
    "        data = data.to(device)\n",
    "\n",
    "        # Sécurité NNConv\n",
    "        assert data.edge_attr is not None\n",
    "        assert data.edge_attr.dim() == 2\n",
    "        assert data.edge_attr.size(0) == data.edge_index.size(1)\n",
    "        data.edge_attr = data.edge_attr.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Encodage VGAE (NNConv utilise edge_attr)\n",
    "        z = model.encode(\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.edge_attr\n",
    "        )\n",
    "        # Loss VGAE = reconstruction + KL\n",
    "        recon_loss = model.recon_loss(z, data.edge_index) / data.num_nodes  # normalisation\n",
    "        kl_loss = model.kl_loss() / data.num_nodes  # normalisation\n",
    "        loss = recon_loss + kl_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # ===== VALIDATION SUR LE FUTUR (SANS BACKPROP) =====\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            data.edge_attr = data.edge_attr.float()\n",
    "\n",
    "            z = model.encode(\n",
    "                data.x,\n",
    "                data.edge_index,\n",
    "                data.edge_attr\n",
    "            )\n",
    "\n",
    "            recon_loss = model.recon_loss(z, data.edge_index) / data.num_nodes  # normalisation\n",
    "            kl_loss = model.kl_loss() / data.num_nodes\n",
    "\n",
    "            val_loss += (recon_loss + kl_loss).item()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:03d} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "    # ===== EARLY STOPPING TEMPOREL =====\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_vgae_nnconv.pt\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14719137",
   "metadata": {},
   "source": [
    "## Évaluer sur le graphe test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8848086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11888/3373473276.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_vgae_nnconv.pt\"))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [113290, 21] but got: [113290, 6].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m      8\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     recon_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mrecon_loss(z, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m     17\u001b[0m     kl_loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mkl_loss() \u001b[38;5;241m/\u001b[39m data\u001b[38;5;241m.\u001b[39mnum_nodes\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/nn/models/autoencoder.py:169\u001b[0m, in \u001b[0;36mVGAE.encode\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__mu__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logstd__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logstd__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logstd__\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mMAX_LOGSTD)\n\u001b[1;32m    171\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparametrize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__mu__, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__logstd__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[53], line 43\u001b[0m, in \u001b[0;36mNNConvEncoder.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Couche 1\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Mu et LogVar pour VGAE\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     mu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_mu(x, edge_index, edge_attr)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/nn/conv/nn_conv.py:108\u001b[0m, in \u001b[0;36mNNConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[1;32m    105\u001b[0m     x \u001b[38;5;241m=\u001b[39m (x, x)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_weight:\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.nn_conv_NNConv_propagate_ub6h5rtt.py:183\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, edge_attr, size)\u001b[0m\n\u001b[1;32m    174\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    175\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    176\u001b[0m                 edge_attr\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_attr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mdim_size,\n\u001b[1;32m    180\u001b[0m             )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# End Message Forward Pre Hook #########################################\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Begin Message Forward Hook ###########################################\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/nn/conv/nn_conv.py:122\u001b[0m, in \u001b[0;36mNNConv.message\u001b[0;34m(self, x_j, edge_attr)\u001b[0m\n\u001b[1;32m    120\u001b[0m weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn(edge_attr)\n\u001b[1;32m    121\u001b[0m weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels_l, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [113290, 21] but got: [113290, 6]."
     ]
    }
   ],
   "source": [
    "# Charger le meilleur modèle\n",
    "model.load_state_dict(torch.load(\"best_vgae_nnconv.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        z = model.encode(\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.edge_attr\n",
    "        )\n",
    "\n",
    "        recon_loss = model.recon_loss(z, data.edge_index) / data.num_nodes\n",
    "        kl_loss = model.kl_loss() / data.num_nodes\n",
    "\n",
    "        test_loss += (recon_loss + kl_loss).item()\n",
    "\n",
    "print(f\"Final Test Loss: {test_loss:.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VGAE",
   "language": "python",
   "name": "vgae-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
